---
title: "Downloading and Processing POLIS Data"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Downloading and Processing POLIS Data}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>")
```

```{r setup, echo=FALSE}
library(tidypolis)
```

## Introduction

The Surveillance, Innovation, and Research (SIR) Team within the Polio Eradication Branch at CDC obtains global polio data from [POLIS](https://extranet.who.int/polis/Account/Login). Collaborators outside of CDC who wish to download and process global polio data using the tidypolis package must have access to POLIS beforehand, as well obtain a POLIS API key.

This guide is tailored for collaborators who wish to use the sirfunctions package to analyze global polio data and have access to data in POLIS.

## Getting Started
Ensure that you have a valid POLIS API key, this can be obtained by contacting **Minh-Ly Pham** [phamm\@who.int](mailto:phamm@who.int){.email} 

### Setting up your POLIS folder {#polis-folder-setup}
Choose a location for your POLIS data folder on your local machine, it is suggested that you keep this folder on your desktop.

```
library(tidypolis)
init_tidypolis <- (
    polis_folder = "path/to/POLIS", #replace with your file path
    edav = F, #keep as F
    api_debug = F #set to T to log individual API calls
    )
```

This function will create a POLIS folder if one doesn't exist or connect to an already existing POLIS folder. If creating a folder you will be required to supply a valid POLIS API key. If the folder already exists your API key will be validated with POLIS. (Note: if POLIS is offline for any reason, ie maintenance, you will be unable to validate your API key)

In creating your POLIS folder your API key will be stored in 'creds.rds' within your POLIS folder

### Downloading Global Polio Data {#download-polis-data}
Once you've created or connected to a POLIS folder you can download data via the POLIS API.

```
 get_polis_data()
```
Running this function will download the following tables:

1. activity
2. case
3. environmental_sample
4. human_specimen
5. im
6. lqas
7. sub_activity
8. virus

The first download will pull the entirety of each table. Subsequent downloads will only pull updated records for tables that contain a unique identifier and updated date fields. 

POLIS population data can also be downloaded with `get_polis_data()`

```
get_polis_data(type = "pop)
```

This will download the population dataset into the same location as the other POLIS tables.

### Pre-processing Data

## Set-up for processing
In order to fully process POLIS data you will need the following:

1. Global WHO geodatabase - this can be obtained by anyone with POLIS access, contact **Oluwadamilola Sonoiki** [sonoikio\@who.int](mailto:sonoikio@who.int){.email}
2. Static AFP and SIA data pre-2020 - this can be obtained by contacting **Stephanie Kovacs** at [uvx4\@cdc.gov](mailto:uvx4@cdc.gov){.email}

When you have these data then you can do the following:

- Process shapefiles using the `preprocess_spatial` function in tidypolis:

```
preprocess_spatial(
gdb_folder = "path/to/gdb_file.gdb", # replace with real path to the GDB file
output_folder = "path/to/data/spatial", # replace with real path to the spatial folder
edav = FALSE
)
```
This will output three .rds shapefiles, `global.ctry.rds`, `global.prov.rds` and `global.dist.rds`. These three datasets need to be placed in the `misc` folder `POLIS_folder/misc/`.

- Static files: you will need nine static files that will be appended to AFP and SIA data at the end of pre-processing. This is all pre-2020 data that remains static and contains certain hard coded values to correct for old POLIS entries that will not be updated. Six of those files are `afp_linelist_2001-01-01_2012-12-31.rds`, `afp_linelist_2013-01-01_2016-12-31.rds`, `afp_linelist_2017-01-01_2019-12-31.rds`, `other_surveillance_type_linelist_2016_2016.rds`, `other_surveillance_type_linelist_2017_2019.rds`, `sia_2000_2019.rds`. These need to be placed in the `core_files_to_combine` folder `POLIS_folder/data/core_files_to_combine/`. The other three static files are `crosswalk.rds`, `env_sites.rds` and `nopv_emg.table.rds` which all need to go in the `misc` folder.

Once you have created and obtained these datasets you can begin pre-processing.

## Processing POLIS data


